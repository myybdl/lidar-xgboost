{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.训练 / 测试数据集\n",
    "### 1.1 数据分析\n",
    "\n",
    "数据集由两部分组成 - 一个用于训练和测试，另一个用于最终独立的精确度测试。它们是在城区选定的区域\n",
    "训练测试集有268 523个点，占地面积41 379平米。\n",
    "下一步，我们读入和分析 __Train_Test_Area.csv__ 数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>R</th>\n",
       "      <th>G</th>\n",
       "      <th>B</th>\n",
       "      <th>PointSourceId</th>\n",
       "      <th>ScanAngleRank</th>\n",
       "      <th>ScanDirectionFlag</th>\n",
       "      <th>NumberOfReturns</th>\n",
       "      <th>ReturnNumber</th>\n",
       "      <th>Intensity</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>588532.900024</td>\n",
       "      <td>3.415956e+06</td>\n",
       "      <td>64.720001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>588533.000031</td>\n",
       "      <td>3.415956e+06</td>\n",
       "      <td>64.820000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>588533.120026</td>\n",
       "      <td>3.415956e+06</td>\n",
       "      <td>64.770004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>588533.190033</td>\n",
       "      <td>3.415956e+06</td>\n",
       "      <td>64.739998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>588533.280029</td>\n",
       "      <td>3.415956e+06</td>\n",
       "      <td>64.809998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>588533.420044</td>\n",
       "      <td>3.415956e+06</td>\n",
       "      <td>64.800003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>588533.470032</td>\n",
       "      <td>3.415955e+06</td>\n",
       "      <td>64.779999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>588533.600037</td>\n",
       "      <td>3.415955e+06</td>\n",
       "      <td>64.770004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>588533.710022</td>\n",
       "      <td>3.415955e+06</td>\n",
       "      <td>64.820000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>588533.890015</td>\n",
       "      <td>3.415955e+06</td>\n",
       "      <td>64.779999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X             Y          Z  R  G  B  PointSourceId  \\\n",
       "0  588532.900024  3.415956e+06  64.720001  0  0  0            6.0   \n",
       "1  588533.000031  3.415956e+06  64.820000  0  0  0            6.0   \n",
       "2  588533.120026  3.415956e+06  64.770004  0  0  0            6.0   \n",
       "3  588533.190033  3.415956e+06  64.739998  0  0  0            6.0   \n",
       "4  588533.280029  3.415956e+06  64.809998  0  0  0            6.0   \n",
       "5  588533.420044  3.415956e+06  64.800003  0  0  0            6.0   \n",
       "6  588533.470032  3.415955e+06  64.779999  0  0  0            6.0   \n",
       "7  588533.600037  3.415955e+06  64.770004  0  0  0            6.0   \n",
       "8  588533.710022  3.415955e+06  64.820000  0  0  0            6.0   \n",
       "9  588533.890015  3.415955e+06  64.779999  0  0  0            6.0   \n",
       "\n",
       "   ScanAngleRank  ScanDirectionFlag  NumberOfReturns  ReturnNumber  Intensity  \\\n",
       "0              0                  0              2.0           1.0       38.0   \n",
       "1              0                  0              2.0           1.0       71.0   \n",
       "2              0                  0              2.0           1.0      165.0   \n",
       "3              0                  0              2.0           1.0       80.0   \n",
       "4              0                  0              2.0           1.0       14.0   \n",
       "5              0                  0              2.0           1.0      156.0   \n",
       "6              0                  0              2.0           1.0       53.0   \n",
       "7              0                  0              2.0           1.0       26.0   \n",
       "8              0                  0              2.0           1.0      156.0   \n",
       "9              0                  0              2.0           1.0       15.0   \n",
       "\n",
       "   Classification  \n",
       "0            16.0  \n",
       "1            16.0  \n",
       "2            16.0  \n",
       "3            16.0  \n",
       "4            16.0  \n",
       "5            16.0  \n",
       "6            16.0  \n",
       "7            16.0  \n",
       "8            16.0  \n",
       "9            16.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_area = pd.read_csv('data/cz_1-9-ml.csv', header=0, delimiter=',')\n",
    "tt_area.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__LiDAR__ 激光点云每个点的属性定义:\n",
    "\n",
    "* __X__,__Y__ - 点的平面位置坐标,\n",
    "* __Z__ - 点的高程数据,\n",
    "* __R__,__G__,__B__ - 附加的R,G,B颜色值,\n",
    "* __PointSourceId__ - 采集来源的唯一识别值,\n",
    "* __ScanAngleRank__ - 扫描斜角,\n",
    "* __ScanDirectionFlag__ - Direction the laser scanning mirror was traveling at the time of the output laser pulse,\n",
    "* __NumberOfReturns__ - 回波次数,\n",
    "* __Intensity__ - 强度,\n",
    "* __Classification__ - 分类，如地面、植被等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 858414 entries, 0 to 858413\n",
      "Data columns (total 13 columns):\n",
      "X                    858414 non-null float64\n",
      "Y                    858414 non-null float64\n",
      "Z                    858414 non-null float64\n",
      "R                    858414 non-null int64\n",
      "G                    858414 non-null int64\n",
      "B                    858414 non-null int64\n",
      "PointSourceId        858414 non-null float64\n",
      "ScanAngleRank        858414 non-null int64\n",
      "ScanDirectionFlag    858414 non-null int64\n",
      "NumberOfReturns      858414 non-null float64\n",
      "ReturnNumber         858414 non-null float64\n",
      "Intensity            858414 non-null float64\n",
      "Classification       858414 non-null float64\n",
      "dtypes: float64(8), int64(5)\n",
      "memory usage: 85.1 MB\n"
     ]
    }
   ],
   "source": [
    "tt_area.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X                    0\n",
       "Y                    0\n",
       "Z                    0\n",
       "R                    0\n",
       "G                    0\n",
       "B                    0\n",
       "PointSourceId        0\n",
       "ScanAngleRank        0\n",
       "ScanDirectionFlag    0\n",
       "NumberOfReturns      0\n",
       "ReturnNumber         0\n",
       "Intensity            0\n",
       "Classification       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_area.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are only numerical features and that there are no null values within all data, so we can proceed with further analysis.\n",
    "我们看到，只有数值特征，也没有空值。可以做进一步的分析了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X                     6830\n",
       "Y                    13589\n",
       "Z                     2940\n",
       "R                        1\n",
       "G                        1\n",
       "B                        1\n",
       "PointSourceId            1\n",
       "ScanAngleRank            1\n",
       "ScanDirectionFlag        1\n",
       "NumberOfReturns          3\n",
       "ReturnNumber             2\n",
       "Intensity              256\n",
       "Classification           8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_area.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>R</th>\n",
       "      <th>G</th>\n",
       "      <th>B</th>\n",
       "      <th>PointSourceId</th>\n",
       "      <th>ScanAngleRank</th>\n",
       "      <th>ScanDirectionFlag</th>\n",
       "      <th>NumberOfReturns</th>\n",
       "      <th>ReturnNumber</th>\n",
       "      <th>Intensity</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>858414.000000</td>\n",
       "      <td>8.584140e+05</td>\n",
       "      <td>858414.000000</td>\n",
       "      <td>858414.0</td>\n",
       "      <td>858414.0</td>\n",
       "      <td>858414.0</td>\n",
       "      <td>858414.0</td>\n",
       "      <td>858414.0</td>\n",
       "      <td>858414.0</td>\n",
       "      <td>858414.000000</td>\n",
       "      <td>858414.000000</td>\n",
       "      <td>858414.000000</td>\n",
       "      <td>858414.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>588568.460381</td>\n",
       "      <td>3.415908e+06</td>\n",
       "      <td>52.499320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.458038</td>\n",
       "      <td>1.228165</td>\n",
       "      <td>188.431102</td>\n",
       "      <td>3.662884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.605081</td>\n",
       "      <td>3.288761e+01</td>\n",
       "      <td>2.801689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.558350</td>\n",
       "      <td>0.419650</td>\n",
       "      <td>41.526994</td>\n",
       "      <td>1.500418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>588532.880035</td>\n",
       "      <td>3.415827e+06</td>\n",
       "      <td>45.310001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>588553.660034</td>\n",
       "      <td>3.415884e+06</td>\n",
       "      <td>51.150002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>588569.050034</td>\n",
       "      <td>3.415911e+06</td>\n",
       "      <td>52.439999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>588583.510025</td>\n",
       "      <td>3.415936e+06</td>\n",
       "      <td>54.010002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>588601.170029</td>\n",
       "      <td>3.415963e+06</td>\n",
       "      <td>77.779999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   X             Y              Z         R         G  \\\n",
       "count  858414.000000  8.584140e+05  858414.000000  858414.0  858414.0   \n",
       "mean   588568.460381  3.415908e+06      52.499320       0.0       0.0   \n",
       "std        18.605081  3.288761e+01       2.801689       0.0       0.0   \n",
       "min    588532.880035  3.415827e+06      45.310001       0.0       0.0   \n",
       "25%    588553.660034  3.415884e+06      51.150002       0.0       0.0   \n",
       "50%    588569.050034  3.415911e+06      52.439999       0.0       0.0   \n",
       "75%    588583.510025  3.415936e+06      54.010002       0.0       0.0   \n",
       "max    588601.170029  3.415963e+06      77.779999       0.0       0.0   \n",
       "\n",
       "              B  PointSourceId  ScanAngleRank  ScanDirectionFlag  \\\n",
       "count  858414.0       858414.0       858414.0           858414.0   \n",
       "mean        0.0            6.0            0.0                0.0   \n",
       "std         0.0            0.0            0.0                0.0   \n",
       "min         0.0            6.0            0.0                0.0   \n",
       "25%         0.0            6.0            0.0                0.0   \n",
       "50%         0.0            6.0            0.0                0.0   \n",
       "75%         0.0            6.0            0.0                0.0   \n",
       "max         0.0            6.0            0.0                0.0   \n",
       "\n",
       "       NumberOfReturns   ReturnNumber      Intensity  Classification  \n",
       "count    858414.000000  858414.000000  858414.000000   858414.000000  \n",
       "mean          1.458038       1.228165     188.431102        3.662884  \n",
       "std           0.558350       0.419650      41.526994        1.500418  \n",
       "min           1.000000       1.000000      10.000000        2.000000  \n",
       "25%           1.000000       1.000000     162.000000        3.000000  \n",
       "50%           1.000000       1.000000     205.000000        4.000000  \n",
       "75%           2.000000       1.000000     217.000000        4.000000  \n",
       "max           3.000000       2.000000     276.000000       20.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_area.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面，我们为后续预测研究特征重要程度。\n",
    "* 因为 __'PointSourceId'__ and __'ScanDirectionFlag'__ 列只有唯一的一个值，我们确信可以删除它们。\n",
    "* 另外， __'X'__ and __'Y'__ 坐标对每个点的值都不同，而且与不同空间区域无关也应当删除。\n",
    "\n",
    "We will use __Univariate Selection__ to confirm our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>R</th>\n",
       "      <th>G</th>\n",
       "      <th>B</th>\n",
       "      <th>PointSourceId</th>\n",
       "      <th>ScanAngleRank</th>\n",
       "      <th>ScanDirectionFlag</th>\n",
       "      <th>NumberOfReturns</th>\n",
       "      <th>ReturnNumber</th>\n",
       "      <th>Intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>588532.900024</td>\n",
       "      <td>3.415956e+06</td>\n",
       "      <td>64.720001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>588533.000031</td>\n",
       "      <td>3.415956e+06</td>\n",
       "      <td>64.820000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>588533.120026</td>\n",
       "      <td>3.415956e+06</td>\n",
       "      <td>64.770004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>588533.190033</td>\n",
       "      <td>3.415956e+06</td>\n",
       "      <td>64.739998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>588533.280029</td>\n",
       "      <td>3.415956e+06</td>\n",
       "      <td>64.809998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X             Y          Z  R  G  B  PointSourceId  \\\n",
       "0  588532.900024  3.415956e+06  64.720001  0  0  0            6.0   \n",
       "1  588533.000031  3.415956e+06  64.820000  0  0  0            6.0   \n",
       "2  588533.120026  3.415956e+06  64.770004  0  0  0            6.0   \n",
       "3  588533.190033  3.415956e+06  64.739998  0  0  0            6.0   \n",
       "4  588533.280029  3.415956e+06  64.809998  0  0  0            6.0   \n",
       "\n",
       "   ScanAngleRank  ScanDirectionFlag  NumberOfReturns  ReturnNumber  Intensity  \n",
       "0              0                  0              2.0           1.0       38.0  \n",
       "1              0                  0              2.0           1.0       71.0  \n",
       "2              0                  0              2.0           1.0      165.0  \n",
       "3              0                  0              2.0           1.0       80.0  \n",
       "4              0                  0              2.0           1.0       14.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tt_area.iloc[:,0:12]\n",
    "y = tt_area.iloc[:,12]\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>R</th>\n",
       "      <th>G</th>\n",
       "      <th>B</th>\n",
       "      <th>PointSourceId</th>\n",
       "      <th>ScanAngleRank</th>\n",
       "      <th>ScanDirectionFlag</th>\n",
       "      <th>NumberOfReturns</th>\n",
       "      <th>ReturnNumber</th>\n",
       "      <th>Intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>588532.900024</td>\n",
       "      <td>3.415956e+06</td>\n",
       "      <td>64.720001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>588533.000031</td>\n",
       "      <td>3.415956e+06</td>\n",
       "      <td>64.820000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>588533.120026</td>\n",
       "      <td>3.415956e+06</td>\n",
       "      <td>64.770004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>588533.190033</td>\n",
       "      <td>3.415956e+06</td>\n",
       "      <td>64.739998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>588533.280029</td>\n",
       "      <td>3.415956e+06</td>\n",
       "      <td>64.809998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X             Y          Z  R  G  B  PointSourceId  \\\n",
       "0  588532.900024  3.415956e+06  64.720001  0  0  0            6.0   \n",
       "1  588533.000031  3.415956e+06  64.820000  0  0  0            6.0   \n",
       "2  588533.120026  3.415956e+06  64.770004  0  0  0            6.0   \n",
       "3  588533.190033  3.415956e+06  64.739998  0  0  0            6.0   \n",
       "4  588533.280029  3.415956e+06  64.809998  0  0  0            6.0   \n",
       "\n",
       "   ScanAngleRank  ScanDirectionFlag  NumberOfReturns  ReturnNumber  Intensity  \n",
       "0              0                  0              2.0           1.0       38.0  \n",
       "1              0                  0              2.0           1.0       71.0  \n",
       "2              0                  0              2.0           1.0      165.0  \n",
       "3              0                  0              2.0           1.0       80.0  \n",
       "4              0                  0              2.0           1.0       14.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['ScanAngleRank'] = X['ScanAngleRank'].abs() # 单变量特征选择（Univariate Selection）需要正数值\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn中的单变量特征选择\n",
    "单变量的特征选择是通过基于一些单变量的统计度量方法来选择最好的特征，比如卡方检测等。Scikit-learn 将单变量特征选择的学习器作为实现了 transform方法的对象：\n",
    "\n",
    "sklearn中实现的方法有:\n",
    "\n",
    "* SelectKBest 保留评分最高的 K 个特征\n",
    "* SelectPercentile 保留最高得分百分比之几的特征\n",
    "* 对每个特征应用常见的单变量统计测试: 假阳性率（false positive rate） SelectFpr, 伪发现率（false discovery rate） SelectFdr , 或者族系误差（family wise error） SelectFwe 。\n",
    "* GenericUnivariateSelect 允许使用可配置方法来进行单变量特征选择。它允许超参数搜索评估器来选择最好的单变量特征。\n",
    "\n",
    "这些对象将得分函数作为输入，返回单变量的得分和 p 值 （或者仅仅是 SelectKBest 和 SelectPercentile 的分数）:\n",
    "\n",
    "* 对于回归: f_regression , mutual_info_regression\n",
    "* 对于分类: chi2 , f_classif , mutual_info_classif\n",
    "\n",
    "这些基于 F-test 的方法计算两个随机变量之间的线性相关程度。另一方面，mutual information methods（mutual information : 互信息）能够计算任何种类的统计相关性，但是作为非参数的方法，互信息需要更多的样本来进行准确的估计。\n",
    "\n",
    "稀疏数据的特征选择\n",
    "\n",
    "如果你使用的是稀疏的数据 (例如数据可以由稀疏矩阵来表示), \n",
    "chi2 , mutual_info_regression , mutual_info_classif 可以处理数据并保持它的稀疏性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从12个特征中选择8个，推测可能会去掉前面提到的四个，经典的卡方检验是检验定性自变量对定性因变量的相关性。\n",
    "test = SelectKBest(score_func=chi2, k=8)\n",
    "fit = test.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.111e+01 1.074e+01 7.531e+04       nan       nan       nan 0.000e+00\n",
      "       nan       nan 8.034e+03 8.182e+03 6.604e+05]\n"
     ]
    }
   ],
   "source": [
    "print(fit.scores_) # 输出12个特征的得分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.885e+05 3.416e+06 6.472e+01 6.000e+00 0.000e+00 2.000e+00 1.000e+00\n",
      "  3.800e+01]\n",
      " [5.885e+05 3.416e+06 6.482e+01 6.000e+00 0.000e+00 2.000e+00 1.000e+00\n",
      "  7.100e+01]\n",
      " [5.885e+05 3.416e+06 6.477e+01 6.000e+00 0.000e+00 2.000e+00 1.000e+00\n",
      "  1.650e+02]\n",
      " [5.885e+05 3.416e+06 6.474e+01 6.000e+00 0.000e+00 2.000e+00 1.000e+00\n",
      "  8.000e+01]\n",
      " [5.885e+05 3.416e+06 6.481e+01 6.000e+00 0.000e+00 2.000e+00 1.000e+00\n",
      "  1.400e+01]\n",
      " [5.885e+05 3.416e+06 6.480e+01 6.000e+00 0.000e+00 2.000e+00 1.000e+00\n",
      "  1.560e+02]]\n"
     ]
    }
   ],
   "source": [
    "features = fit.transform(X)\n",
    "print(features[0:6,:]) # summarize selected features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8列：Z，R，G，B，扫描倾角，回波数，返回值，强度\n",
    "\n",
    "我们看到 __'PointSourceId'__ 和 __'ScanDirectionFlag'__ 几乎是空值，并且 __'X'__ 和 __'Y'__ 也不在前8名特征选择得分中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 858414 entries, 0 to 858413\n",
      "Data columns (total 13 columns):\n",
      "X                    858414 non-null float64\n",
      "Y                    858414 non-null float64\n",
      "Z                    858414 non-null float64\n",
      "R                    858414 non-null int64\n",
      "G                    858414 non-null int64\n",
      "B                    858414 non-null int64\n",
      "PointSourceId        858414 non-null float64\n",
      "ScanAngleRank        858414 non-null int64\n",
      "ScanDirectionFlag    858414 non-null int64\n",
      "NumberOfReturns      858414 non-null float64\n",
      "ReturnNumber         858414 non-null float64\n",
      "Intensity            858414 non-null float64\n",
      "Classification       858414 non-null float64\n",
      "dtypes: float64(8), int64(5)\n",
      "memory usage: 85.1 MB\n"
     ]
    }
   ],
   "source": [
    "tt_area.info()\n",
    "tt_area.drop(['PointSourceId', 'ScanDirectionFlag', 'X', 'Y'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面分析 __'Classification'__ 特征。\n",
    "\n",
    "一般的LiDAR数据分类有18种类别代码：\n",
    "* __0__ / __1__ - 尚未分类 / 未指定,\n",
    "* __2__ - 地面,\n",
    "* __3__ / __4__ / __5__ - 低植被 / 中植被 / 高植被,\n",
    "* __6__ - 建筑,\n",
    "* __7__ - 噪音,\n",
    "* __8__ - Model Key,\n",
    "* __9__ - 水,\n",
    "* __10__ / __11__ - 铁路 / 道路(表面),\n",
    "* __12__ - Overlap (保留),\n",
    "* __13__ / __14__ / __15__ / __16__ - Wire-Guard / Wire-Conductor / Transmission Tower / Wire-Connector\n",
    "* __17__ - Bridge Deck\n",
    "* __18__ - High Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.,  3.,  4.,  5.,  8., 16., 17., 20.]),\n",
       " array([137357, 207484, 418676,  80790,   8045,   2272,   2687,   1103],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(tt_area.Classification, return_counts=True) # 计算每个类别有多少记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(tt_area.Classification, color = 'skyblue')\n",
    "\n",
    "plt.title(u'LiDAR - 点云分类别直方图')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "如图所示，极大比例的是地面(2)类别点。这是一个失调的比例，会明显降低性能。另外，也没有1和8以上的类别。\n",
    "\n",
    "### 1.2 数据采样\n",
    "\n",
    "对主要类别 - 地面（2）采用 __down-sampling__ ，对其它了别采用 __up-sampling__ , 设置所有类别的采样数量匹配 __5000 features__ 。\n",
    "针对少数类的向上采样和针对多数类的向下采样都使用来自 https://elitedatascience.com/imbalanced-classes 模式。\n",
    "首先，我们必须把数据切分成 __train / test__ 数据集，以免干扰后面基于测试数据的模型精确度评估。\n",
    "\n",
    "关于不平衡类别处理参考文章 https://yq.aliyun.com/articles/226016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Z</th>\n",
       "      <th>R</th>\n",
       "      <th>G</th>\n",
       "      <th>B</th>\n",
       "      <th>ScanAngleRank</th>\n",
       "      <th>NumberOfReturns</th>\n",
       "      <th>ReturnNumber</th>\n",
       "      <th>Intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64.720001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.820000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64.770004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.739998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64.809998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Z  R  G  B  ScanAngleRank  NumberOfReturns  ReturnNumber  Intensity\n",
       "0  64.720001  0  0  0              0              2.0           1.0       38.0\n",
       "1  64.820000  0  0  0              0              2.0           1.0       71.0\n",
       "2  64.770004  0  0  0              0              2.0           1.0      165.0\n",
       "3  64.739998  0  0  0              0              2.0           1.0       80.0\n",
       "4  64.809998  0  0  0              0              2.0           1.0       14.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tt_area.iloc[:,0:8]\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16.0\n",
       "1    16.0\n",
       "2    16.0\n",
       "3    16.0\n",
       "4    16.0\n",
       "Name: Classification, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = tt_area.iloc[:,8]\n",
    "y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we concatenate our X_train and y_train data in order to handle our imbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Z  R  G  B  ScanAngleRank  NumberOfReturns  ReturnNumber  \\\n",
      "44549   48.200001  0  0  0              0              2.0           2.0   \n",
      "536127  54.639999  0  0  0              0              1.0           1.0   \n",
      "161307  55.750000  0  0  0              0              1.0           1.0   \n",
      "778375  51.730000  0  0  0              0              2.0           1.0   \n",
      "820796  54.630001  0  0  0              0              2.0           1.0   \n",
      "\n",
      "        Intensity  Classification  \n",
      "44549       210.0             2.0  \n",
      "536127      205.0             4.0  \n",
      "161307      206.0             5.0  \n",
      "778375      171.0             4.0  \n",
      "820796      148.0             4.0  \n"
     ]
    }
   ],
   "source": [
    "tt_area_train = pd.concat([X_train, y_train], axis=1, join='inner')\n",
    "print(tt_area_train.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0     279992\n",
      "3.0     139185\n",
      "2.0      92094\n",
      "5.0      54360\n",
      "8.0       5410\n",
      "17.0      1792\n",
      "16.0      1559\n",
      "20.0       745\n",
      "Name: Classification, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(tt_area_train.Classification.value_counts()) # train data imbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 123\n",
    "n_samples = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60000 entries, 21068 to 19532\n",
      "Data columns (total 9 columns):\n",
      "Z                  60000 non-null float64\n",
      "R                  60000 non-null int64\n",
      "G                  60000 non-null int64\n",
      "B                  60000 non-null int64\n",
      "ScanAngleRank      60000 non-null int64\n",
      "NumberOfReturns    60000 non-null float64\n",
      "ReturnNumber       60000 non-null float64\n",
      "Intensity          60000 non-null float64\n",
      "Classification     60000 non-null float64\n",
      "dtypes: float64(5), int64(4)\n",
      "memory usage: 4.6 MB\n"
     ]
    }
   ],
   "source": [
    "tt_area_majority_2 = tt_area_train[tt_area_train.Classification==2] # 提取地面特征记录\n",
    "# 地面点从??万减到6万\n",
    "tt_area_majority_2_upsampled = resample(tt_area_majority_2, \n",
    "                                 replace=False,              # 采样替换，采用切片方式；采样数不能超出原来数据表记录数\n",
    "                                 n_samples=n_samples,        # n_samples chosen for down-sampling\n",
    "                                 random_state=random_state)  # reproducible results\n",
    "tt_area_majority_2_upsampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60000 entries, 384572 to 386245\n",
      "Data columns (total 9 columns):\n",
      "Z                  60000 non-null float64\n",
      "R                  60000 non-null int64\n",
      "G                  60000 non-null int64\n",
      "B                  60000 non-null int64\n",
      "ScanAngleRank      60000 non-null int64\n",
      "NumberOfReturns    60000 non-null float64\n",
      "ReturnNumber       60000 non-null float64\n",
      "Intensity          60000 non-null float64\n",
      "Classification     60000 non-null float64\n",
      "dtypes: float64(5), int64(4)\n",
      "memory usage: 4.6 MB\n"
     ]
    }
   ],
   "source": [
    "tt_area_majority_3 = tt_area_train[tt_area_train.Classification==3] # 提取地面特征记录\n",
    "# 地面点从??万减到6万\n",
    "tt_area_majority_3_upsampled = resample(tt_area_majority_3, \n",
    "                                 replace=False,              # 采样替换，采用切片方式；采样数不能超出原来数据表记录数\n",
    "                                 n_samples=n_samples,        # n_samples chosen for down-sampling\n",
    "                                 random_state=random_state)  # reproducible results\n",
    "tt_area_majority_3_upsampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60000 entries, 730841 to 683582\n",
      "Data columns (total 9 columns):\n",
      "Z                  60000 non-null float64\n",
      "R                  60000 non-null int64\n",
      "G                  60000 non-null int64\n",
      "B                  60000 non-null int64\n",
      "ScanAngleRank      60000 non-null int64\n",
      "NumberOfReturns    60000 non-null float64\n",
      "ReturnNumber       60000 non-null float64\n",
      "Intensity          60000 non-null float64\n",
      "Classification     60000 non-null float64\n",
      "dtypes: float64(5), int64(4)\n",
      "memory usage: 4.6 MB\n"
     ]
    }
   ],
   "source": [
    "tt_area_majority_4 = tt_area_train[tt_area_train.Classification==4] # 提取地面特征记录\n",
    "# 地面点从??万减到6万\n",
    "tt_area_majority_4_upsampled = resample(tt_area_majority_4, \n",
    "                                 replace=False,              # 采样替换，采用切片方式；采样数不能超出原来数据表记录数\n",
    "                                 n_samples=n_samples,        # n_samples chosen for down-sampling\n",
    "                                 random_state=random_state)  # reproducible results\n",
    "tt_area_majority_4_upsampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_area_minority_5 = tt_area_train[tt_area_train.Classification==5] # extraction of Never classified features\n",
    "#tt_area_minority_3 = tt_area_train[tt_area_train.Classification==3] # extraction of Low Vegetation features\n",
    "#tt_area_minority_4 = tt_area_train[tt_area_train.Classification==4] # extraction of Medium Vegetation features\n",
    "tt_area_minority_8 = tt_area_train[tt_area_train.Classification==8] # extraction of High Vegetation features\n",
    "tt_area_minority_16 = tt_area_train[tt_area_train.Classification==16] # extraction of Building features\n",
    "tt_area_minority_17 = tt_area_train[tt_area_train.Classification==17] # extraction of Noise features\n",
    "tt_area_minority_20 = tt_area_train[tt_area_train.Classification==20] # extraction of Overlap (Reserved) features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 少数类增加到与多数类同样的样本数2.5万\n",
    "tt_area_minority_5_upsampled = resample(tt_area_minority_5, \n",
    "                                 replace=True,               # sample with replacement\n",
    "                                 n_samples=n_samples,        # to match majority class\n",
    "                                 random_state=random_state)  # reproducible results\n",
    "\n",
    "#tt_area_minority_3_upsampled = resample(tt_area_minority_3, \n",
    "#                                 replace=True,               # sample with replacement\n",
    "#                                 n_samples=n_samples,        # to match majority class\n",
    "#                                 random_state=random_state)  # reproducible results\n",
    "\n",
    "#tt_area_minority_4_upsampled = resample(tt_area_minority_4, \n",
    "#                                 replace=True,               # sample with replacement\n",
    "#                                 n_samples=n_samples,        # to match majority class\n",
    "#                                 random_state=random_state)  # reproducible results\n",
    "\n",
    "tt_area_minority_8_upsampled = resample(tt_area_minority_8, \n",
    "                                 replace=True,               # sample with replacement\n",
    "                                 n_samples=n_samples,        # to match majority class\n",
    "                                 random_state=random_state)  # reproducible results\n",
    "\n",
    "tt_area_minority_16_upsampled = resample(tt_area_minority_16, \n",
    "                                 replace=True,               # sample with replacement\n",
    "                                 n_samples=n_samples,        # to match majority class\n",
    "                                 random_state=random_state)  # reproducible results\n",
    "\n",
    "tt_area_minority_17_upsampled = resample(tt_area_minority_17, \n",
    "                                 replace=True,               # sample with replacement\n",
    "                                 n_samples=n_samples,        # to match majority class\n",
    "                                 random_state=random_state)  # reproducible results\n",
    "\n",
    "tt_area_minority_20_upsampled = resample(tt_area_minority_20, \n",
    "                                 replace=True,               # sample with replacement\n",
    "                                 n_samples=n_samples,        # to match majority class\n",
    "                                 random_state=random_state)  # reproducible results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在合并生成采样数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_area_train_sampled = pd.concat([tt_area_majority_2_upsampled, tt_area_majority_3_upsampled, \n",
    "                                     tt_area_majority_4_upsampled, tt_area_minority_5_upsampled, \n",
    "                                     tt_area_minority_8_upsampled, tt_area_minority_16_upsampled, \n",
    "                                     tt_area_minority_17_upsampled, tt_area_minority_20_upsampled ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载训练数据集有了更多观察值，而各个类别的数据比例都是1:1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 480000 entries, 21068 to 854861\n",
      "Data columns (total 9 columns):\n",
      "Z                  480000 non-null float64\n",
      "R                  480000 non-null int64\n",
      "G                  480000 non-null int64\n",
      "B                  480000 non-null int64\n",
      "ScanAngleRank      480000 non-null int64\n",
      "NumberOfReturns    480000 non-null float64\n",
      "ReturnNumber       480000 non-null float64\n",
      "Intensity          480000 non-null float64\n",
      "Classification     480000 non-null float64\n",
      "dtypes: float64(5), int64(4)\n",
      "memory usage: 36.6 MB\n"
     ]
    }
   ],
   "source": [
    "tt_area_train_sampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0    60000\n",
       "3.0     60000\n",
       "16.0    60000\n",
       "8.0     60000\n",
       "5.0     60000\n",
       "4.0     60000\n",
       "17.0    60000\n",
       "2.0     60000\n",
       "Name: Classification, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_area_train_sampled.Classification.value_counts() # 现在训练数据集有20万个点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tt_area_train_sampled.iloc[:, :8] # 特征数据\n",
    "y_train = tt_area_train_sampled.iloc[:, 8] # 分类数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理=》无量纲化=》区间缩放法：区间缩放法的思路有多种，常见的一种为利用两个最值进行缩放\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\hm1016\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "d:\\miniconda3\\envs\\hm1016\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.228, 0.   , 0.   , ..., 0.   , 0.   , 0.783],\n",
       "       [0.234, 0.   , 0.   , ..., 0.5  , 0.   , 0.482],\n",
       "       [0.198, 0.   , 0.   , ..., 0.5  , 1.   , 0.585],\n",
       "       ...,\n",
       "       [0.139, 0.   , 0.   , ..., 0.   , 0.   , 0.577],\n",
       "       [0.231, 0.   , 0.   , ..., 0.5  , 0.   , 0.538],\n",
       "       [0.018, 0.   , 0.   , ..., 0.   , 0.   , 0.81 ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = mm.fit_transform(X_train) # 采样之后的全部数据集：训练+测试=》再采样\n",
    "X_test = mm.fit_transform(X_test) # sklearn最早分出来的测试集\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 XGBoost - 默认\n",
    "\n",
    "下面我们采用梯度增强算法的一个高级实现 - __XGBoost__ 。\n",
    "\n",
    "先用默认设置(we will work only with scaled data from now on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.52%\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n"
     ]
    }
   ],
   "source": [
    "model_xgb = XGBClassifier()\n",
    "model_xgb.fit(X_train, y_train)\n",
    "y_pred = model_xgb.predict(X_train)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_train, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print(model_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 48.19%\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_xgb.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "超过78%的准确度已经不错。不过有5%的准确度下降，可能有过度拟合的问题。\n",
    "\n",
    "\n",
    "### 1.4 XGBoost - 调参\n",
    "\n",
    "\n",
    "下面调整XGBoost参数，看能否在训练和测试数据上火的更好的准确度。\n",
    "文章 https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/ 中的内容将作为优化的参考。\n",
    "\n",
    "需要执行的几个步骤：\n",
    "\n",
    "1. 选择默认值 __learning rate__ 和 __number of trees__\n",
    "2. 调整 __max_depth__ 和 __min_child_weight__\n",
    "3. 调整 __gamma__\n",
    "4. 调整 __subsample__ 和 __colsample_bytree__\n",
    "5. 调整 __regularization parameters__\n",
    "6. 降低 __learning rate__ 和提升 __more trees__\n",
    "\n",
    "看看更详细的每一步操作方法。\n",
    "\n",
    "首先，设置默认值：\n",
    "* learning rate - 0.1   一般情况下，学习速率的值为0.1。\n",
    "* number of trees - 100,\n",
    "\n",
    "其它参数优化后，会有什么变化呢？\n",
    "\n",
    "下面设置 __GridSearchCV__ 为 __5 cross-validation__ ， __max_depth__ 和 __min_child_weight__ as they will most likely have the highest impact on model outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV] max_depth=5, min_child_weight=1 .................................\n",
      "[CV]  max_depth=5, min_child_weight=1, score=0.6846666666666666, total= 1.9min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.1min remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=1 .................................\n",
      "[CV]  max_depth=5, min_child_weight=1, score=0.6824166666666667, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.2min remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=1 .................................\n",
      "[CV]  max_depth=5, min_child_weight=1, score=0.6852083333333333, total= 2.1min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  6.5min remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=1 .................................\n",
      "[CV] .. max_depth=5, min_child_weight=1, score=0.685625, total= 2.1min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  8.7min remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=1 .................................\n",
      "[CV]  max_depth=5, min_child_weight=1, score=0.68665625, total= 2.1min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 11.0min remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=3 .................................\n",
      "[CV]  max_depth=5, min_child_weight=3, score=0.6848020833333334, total= 2.1min\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 13.3min remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=3 .................................\n",
      "[CV]  max_depth=5, min_child_weight=3, score=0.6824583333333333, total= 2.1min\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 15.5min remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=3 .................................\n",
      "[CV]  max_depth=5, min_child_weight=3, score=0.6854479166666667, total= 2.1min\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 17.8min remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=3 .................................\n",
      "[CV]  max_depth=5, min_child_weight=3, score=0.6853645833333334, total= 2.1min\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 20.0min remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=3 .................................\n",
      "[CV]  max_depth=5, min_child_weight=3, score=0.6862708333333334, total= 2.1min\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 22.3min remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV]  max_depth=5, min_child_weight=5, score=0.6845833333333333, total= 2.1min\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed: 24.6min remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV]  max_depth=5, min_child_weight=5, score=0.6820729166666667, total= 2.1min\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed: 26.8min remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV]  max_depth=5, min_child_weight=5, score=0.6860104166666666, total= 2.1min\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed: 29.1min remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV]  max_depth=5, min_child_weight=5, score=0.6853229166666667, total= 2.1min\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed: 31.3min remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV]  max_depth=5, min_child_weight=5, score=0.6865729166666666, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 33.4min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=1 ................................\n",
      "[CV]  max_depth=10, min_child_weight=1, score=0.7325520833333333, total= 3.6min\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed: 37.3min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=1 ................................\n",
      "[CV]  max_depth=10, min_child_weight=1, score=0.72946875, total= 3.5min\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed: 41.1min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=1 ................................\n",
      "[CV]  max_depth=10, min_child_weight=1, score=0.7304583333333333, total= 3.5min\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed: 44.8min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=1 ................................\n",
      "[CV]  max_depth=10, min_child_weight=1, score=0.73059375, total= 3.5min\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed: 48.6min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=1 ................................\n",
      "[CV]  max_depth=10, min_child_weight=1, score=0.7322916666666667, total= 3.5min\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed: 52.4min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=3 ................................\n",
      "[CV]  max_depth=10, min_child_weight=3, score=0.7318854166666666, total= 3.5min\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed: 56.2min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=3 ................................\n",
      "[CV]  max_depth=10, min_child_weight=3, score=0.7285416666666666, total= 3.5min\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed: 59.9min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=3 ................................\n",
      "[CV] .. max_depth=10, min_child_weight=3, score=0.73175, total= 3.5min\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed: 63.7min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=3 ................................\n",
      "[CV]  max_depth=10, min_child_weight=3, score=0.7302708333333333, total= 3.5min\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed: 67.4min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=3 ................................\n",
      "[CV] .. max_depth=10, min_child_weight=3, score=0.73125, total= 3.5min\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed: 71.2min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=5 ................................\n",
      "[CV] . max_depth=10, min_child_weight=5, score=0.730125, total= 3.5min\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed: 74.9min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=5 ................................\n",
      "[CV]  max_depth=10, min_child_weight=5, score=0.7280729166666666, total= 3.5min\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed: 78.7min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=5 ................................\n",
      "[CV]  max_depth=10, min_child_weight=5, score=0.73046875, total= 3.5min\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed: 82.4min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=5 ................................\n",
      "[CV]  max_depth=10, min_child_weight=5, score=0.7285729166666667, total= 3.5min\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed: 86.2min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=5 ................................\n",
      "[CV]  max_depth=10, min_child_weight=5, score=0.7293541666666666, total= 3.5min\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 89.9min remaining:    0.0s\n",
      "[CV] max_depth=20, min_child_weight=1 ................................\n",
      "[CV]  max_depth=20, min_child_weight=1, score=0.78453125, total= 6.7min\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed: 97.6min remaining:    0.0s\n",
      "[CV] max_depth=20, min_child_weight=1 ................................\n",
      "[CV]  max_depth=20, min_child_weight=1, score=0.7838020833333333, total= 6.8min\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed: 105.3min remaining:    0.0s\n",
      "[CV] max_depth=20, min_child_weight=1 ................................\n",
      "[CV]  max_depth=20, min_child_weight=1, score=0.78396875, total= 6.7min\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed: 113.0min remaining:    0.0s\n",
      "[CV] max_depth=20, min_child_weight=1 ................................\n",
      "[CV]  max_depth=20, min_child_weight=1, score=0.78584375, total= 6.7min\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed: 120.6min remaining:    0.0s\n",
      "[CV] max_depth=20, min_child_weight=1 ................................\n",
      "[CV] .. max_depth=20, min_child_weight=1, score=0.78575, total= 6.8min\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed: 128.3min remaining:    0.0s\n",
      "[CV] max_depth=20, min_child_weight=3 ................................\n",
      "[CV]  max_depth=20, min_child_weight=3, score=0.7806354166666667, total= 6.6min\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed: 135.7min remaining:    0.0s\n",
      "[CV] max_depth=20, min_child_weight=3 ................................\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "params = {\n",
    "    'max_depth':[5,10,20],\n",
    "    'min_child_weight':[1,3,5]\n",
    "}\n",
    "\n",
    "gscv1 = GridSearchCV(estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "                                            colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "                                            missing=None, n_estimators=100, n_jobs=1, nthread=None, \n",
    "                                            objective='multi:softprob', random_state=0, reg_alpha=0, reg_lambda=1,\n",
    "                                            scale_pos_weight=1, seed=None, silent=True, subsample=1),\n",
    "                                            param_grid = params, cv=5, verbose=100)\n",
    "\n",
    "\n",
    "gscv1.fit(X_train,y_train)\n",
    "\n",
    "s = gscv1.grid_scores_.copy()\n",
    "s.sort(key= lambda x: x[1],reverse=True)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see 20 as the optimal value for __max_depth__ and  for __min_child_weight__ and because these are our extreme values we will search for more precise values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(**gscv1.best_params_)\n",
    "params = {'max_depth': [20,30,40,50],\n",
    "         'min_child_weight': [1,2]}\n",
    "gscv2 = GridSearchCV(param_grid=params, estimator=xgb,cv=5, verbose=100)\n",
    "gscv2.fit(X_train,y_train)\n",
    "s = gscv2.grid_scores_.copy()\n",
    "s.sort(key= lambda x: x[1],reverse=True)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We will go one step deeper once more and look for optimum values for max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(**gscv2.best_estimator_.get_params())\n",
    "params = {'max_depth': [50,60,70,80]\n",
    "         }\n",
    "gscv3 = GridSearchCV(param_grid=params, estimator=xgb,cv=5, verbose=100)\n",
    "gscv3.fit(X_train,y_train)\n",
    "s = gscv3.grid_scores_.copy()\n",
    "s.sort(key= lambda x: x[1],reverse=True)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see that picking __50 max_depth__ value was the right way to go. So now we've got the optimum values of __50__ for __max_depth__ and __1__ for __min_child_weight__.\n",
    "\n",
    "Subsequently we will tune __gamma value__ using the parameters already tuned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(**gscv3.best_estimator_.get_params())\n",
    "params = {'gamma':[0.0,0.1,0.2,0.3,0.4]\n",
    "          \n",
    "         }\n",
    "gscv4 = GridSearchCV(param_grid=params, estimator=xgb,cv=5, verbose=100)\n",
    "gscv4.fit(X_train,y_train)\n",
    "s = gscv4.grid_scores_.copy()\n",
    "s.sort(key= lambda x: x[1],reverse=True)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We've got the optimum value of __0.0__ for __gamma__ parameter.\n",
    "\n",
    "Next we will tune __subsample__ and __colsample_bytree__ with values 0.6, 0.7, 0.8, 0.9 for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(**gscv4.best_estimator_.get_params())\n",
    "params = {'subsample':[0.6,0.7,0.8,0.9],\n",
    "         'colsample_bytree':[0.6,0.7,0.8,0.9]\n",
    "\n",
    "         }\n",
    "gscv5 = GridSearchCV(param_grid=params, estimator=xgb,cv=5, verbose=100)\n",
    "gscv5.fit(X_train,y_train)\n",
    "s = gscv5.grid_scores_.copy()\n",
    "s.sort(key= lambda x: x[1],reverse=True)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see that __colsample_bytree__: 0.6 and __subsample__: 0.9 were the most optimum values.\n",
    "\n",
    "Now we will apply regularization (__reg_alpha, reg_lambda__) to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(**gscv5.best_estimator_.get_params())\n",
    "params = {'reg_alpha':[1e-5, 1e-2, 0, 0.1, 1, 100],\n",
    "          \n",
    "        }\n",
    "\n",
    "gscv6 = GridSearchCV(param_grid=params, estimator=xgb,cv=5, verbose=100)\n",
    "gscv6.fit(X_train,y_train)\n",
    "s = gscv6.grid_scores_.copy()\n",
    "s.sort(key= lambda x: x[1],reverse=True)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We've got an extreme value of 1e-05 so we will do more investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(**gscv6.best_estimator_.get_params())\n",
    "params = {'reg_alpha':[1e-9, 1e-7, 1e-5, 1e-3]\n",
    "          \n",
    "        }\n",
    "\n",
    "gscv7 = GridSearchCV(param_grid=params, estimator=xgb,cv=5, verbose=100)\n",
    "gscv7.fit(X_train,y_train)\n",
    "s = gscv7.grid_scores_.copy()\n",
    "s.sort(key= lambda x: x[1],reverse=True)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next we focus on __reg_lambda__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(**gscv7.best_estimator_.get_params())\n",
    "params = {'reg_lambda':[1e-5, 1e-2, 0, 0.1, 1, 100],\n",
    "          \n",
    "        }\n",
    "\n",
    "gscv8 = GridSearchCV(param_grid=params, estimator=xgb,cv=5, verbose=100)\n",
    "gscv8.fit(X_train,y_train)\n",
    "s = gscv8.grid_scores_.copy()\n",
    "s.sort(key= lambda x: x[1],reverse=True)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As well as in reg_alpha we've got the extreme value of 1e-05 so we do more searching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(**gscv8.best_estimator_.get_params())\n",
    "params = {'reg_lambda':[1e-9, 1e-7, 1e-5, 1e-3]\n",
    "          \n",
    "        }\n",
    "\n",
    "gscv9 = GridSearchCV(param_grid=params, estimator=xgb,cv=5, verbose=100)\n",
    "gscv9.fit(X_train,y_train)\n",
    "s = gscv9.grid_scores_.copy()\n",
    "s.sort(key= lambda x: x[1],reverse=True)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see that __creg_alpha__: 1e-05 and __reg_lambda__: 0.001 were the most optimum values.\n",
    "\n",
    "Finally we've achieved our optimal XGBoost algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gscv9.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we should lower the __learning rate__ to 0.01 and add more __trees__ - 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "                           colsample_bytree=0.6, gamma=0.0, learning_rate=0.01,\n",
    "                           max_delta_step=0, max_depth=50, min_child_weight=1, missing=None,\n",
    "                           n_estimators=1000, n_jobs=1, nthread=None,\n",
    "                           objective='multi:softprob', random_state=0, reg_alpha=1e-07,\n",
    "                           reg_lambda=0.001, scale_pos_weight=1, seed=None, silent=True,\n",
    "                           subsample=0.9)\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_train)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_train, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A score of over 87%.\n",
    "\n",
    "Summarizing our tuned XGBoost algorithm got the best score for training and test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.测试数据集\n",
    "\n",
    "### 2.1 数据分析\n",
    "\n",
    "测试区域有46973点云数据，面积9896平米。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_area = pd.read_csv('data/01.Test_Area.csv', header=0, delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_area.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_area.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in test area there are also only numerical features and that there are no null values within all data, so we can proceed with further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_area.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_area.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_area = t_area.drop(['PointSourceId', 'ScanDirectionFlag', 'X', 'Y'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = t_area.iloc[:,0:8]\n",
    "y2 = t_area.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(t_area.Classification, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(t_area.Classification, color = 'skyblue')\n",
    "\n",
    "plt.title('LiDAR points in each class')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = mm.fit_transform(X2) #we scale our data as in the first train/test area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 XGBoost - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_pred = model_xgb.predict(X2)\n",
    "predictions2 = [round(value) for value in y2_pred]\n",
    "accuracy = accuracy_score(y2, predictions2)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 XGBoost - tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_pred = best_model.predict(X2)\n",
    "predictions2 = [round(value) for value in y2_pred]\n",
    "accuracy = accuracy_score(y2, predictions2)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 54% ! So summarizing accuracies on X2, y2 test areas were really low in comparisson to X_test and y_test data from train/test area.\n",
    "\n",
    "We will split our test area dataset to train, test data to see how our optimized XGBoost model works fitted on X2_train, y2_train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size = 0.33)\n",
    "X2_train = mm.fit_transform(X2_train)\n",
    "X2_test = mm.fit_transform(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "                           colsample_bytree=0.6, gamma=0.0, learning_rate=0.01,\n",
    "                           max_delta_step=0, max_depth=50, min_child_weight=1, missing=None,\n",
    "                           n_estimators=1000, n_jobs=1, nthread=None,\n",
    "                           objective='multi:softprob', random_state=0, reg_alpha=1e-07,\n",
    "                           reg_lambda=0.001, scale_pos_weight=1, seed=None, silent=True,\n",
    "                           subsample=0.9)\n",
    "\n",
    "best_model.fit(X2_train, y2_train)\n",
    "y2_pred = best_model.predict(X2_train)\n",
    "predictions = [round(value) for value in y2_pred]\n",
    "accuracy = accuracy_score(y2_train, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have achieved perfect score on train test area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_pred = best_model.predict(X2_test)\n",
    "predictions = [round(value) for value in y2_pred]\n",
    "accuracy = accuracy_score(y2_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And almost 95% on test dataset! In conclusion two factors maybe to blame here.\n",
    "\n",
    "First the chosen features were not optimal and we should try a pick other than __Univariate Selection__.\n",
    "\n",
    "The second is that we only had one train/test area and our test area may have varied too much to achieve good result. With better hardware capabilities we could have chosen over a dozen of train/test areas and fit combined data into our algorithm.\n",
    "\n",
    "To wrap things up there will be consecutive notebook __\"02. XGBoost for Aerial LiDAR Data Classification with extended training dataset\"__ where __XGBoost__ algorithm  will be trained an fit on __6 training areas__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
