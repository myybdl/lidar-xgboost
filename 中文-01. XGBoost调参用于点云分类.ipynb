{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01. XGBoost调参 - 机载LiDAR数据分类¶\n",
    "本文的目的是选择和优化机器学习算法，用于执行机载LiDAR地物分类，使用__*.LAS__文件格式的可用特征。\n",
    "在该在本项目中使用，点云文件需要用 __ArcGIS PRO 2.1.1__ 软件转换为 __*.csv__ 格式。\n",
    "<img src=\"img/LAS_dataset.png\" width=\"80%\">\n",
    "Source: http://pro.arcgis.com/en/pro-app/help/data/las-dataset/GUID-C323587E-81F2-4823-B2E4-2331445BF5D1-web.png\n",
    "\n",
    "\n",
    "<br>\n",
    "### Table of Contents\n",
    "\n",
    "    1.Train / test dataset\n",
    "\n",
    "        1.1 Data analysis\n",
    "        1.2 Data sampling\n",
    "        1.3 XGBoost - default\n",
    "        1.4 XGBoost - tuning\n",
    "    \n",
    "    2.Test dataset\n",
    "    \n",
    "        2.1 Data analysis\n",
    "        2.2 XGBoost - default\n",
    "        2.3 XGBoost - tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.训练 / 验证数据集\n",
    "### 1.1 数据分析\n",
    "\n",
    "数据集由两个区域组成 - 一个用于训练和验证，另一个用于最终独立的精确度测试。它们是在Peplin城区选定的区域。\n",
    "\n",
    "<img src=\"img/Zakres1_2_2d.jpg\" width=\"80%\">\n",
    "\n",
    "训练测试集有268 523个点，占地面积41 379平米。\n",
    "\n",
    "<img src='img/Zakres1_2d.jpg' width=\"80%\">\n",
    "<img src='img/Zakres1_3d.jpg' width=\"80%\">\n",
    "\n",
    "下一步，我们读入和分析 __Train_Test_Area.csv__ 数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>R</th>\n",
       "      <th>G</th>\n",
       "      <th>B</th>\n",
       "      <th>PointSourceId</th>\n",
       "      <th>ScanAngleRank</th>\n",
       "      <th>ScanDirectionFlag</th>\n",
       "      <th>NumberOfReturns</th>\n",
       "      <th>ReturnNumber</th>\n",
       "      <th>Intensity</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>484179.43750</td>\n",
       "      <td>676279.6875</td>\n",
       "      <td>49.340000</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>112</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>484179.31250</td>\n",
       "      <td>676280.0000</td>\n",
       "      <td>49.320000</td>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>115</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>484178.81250</td>\n",
       "      <td>676280.0625</td>\n",
       "      <td>49.310001</td>\n",
       "      <td>123</td>\n",
       "      <td>124</td>\n",
       "      <td>113</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>484178.31250</td>\n",
       "      <td>676280.1250</td>\n",
       "      <td>49.340000</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>112</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>484177.81250</td>\n",
       "      <td>676280.1875</td>\n",
       "      <td>49.320000</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>112</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>484177.31250</td>\n",
       "      <td>676280.1875</td>\n",
       "      <td>49.320000</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>115</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>484176.84375</td>\n",
       "      <td>676280.2500</td>\n",
       "      <td>49.310001</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>115</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>484176.31250</td>\n",
       "      <td>676280.2500</td>\n",
       "      <td>49.340000</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>117</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>484179.12500</td>\n",
       "      <td>676280.3750</td>\n",
       "      <td>49.310001</td>\n",
       "      <td>124</td>\n",
       "      <td>126</td>\n",
       "      <td>115</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>484178.65625</td>\n",
       "      <td>676280.3750</td>\n",
       "      <td>49.320000</td>\n",
       "      <td>128</td>\n",
       "      <td>129</td>\n",
       "      <td>119</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              X            Y          Z    R    G    B  PointSourceId  \\\n",
       "0  484179.43750  676279.6875  49.340000  124  124  112          101.0   \n",
       "1  484179.31250  676280.0000  49.320000  124  125  115          101.0   \n",
       "2  484178.81250  676280.0625  49.310001  123  124  113          101.0   \n",
       "3  484178.31250  676280.1250  49.340000  122  122  112          101.0   \n",
       "4  484177.81250  676280.1875  49.320000  122  122  112          101.0   \n",
       "5  484177.31250  676280.1875  49.320000  125  125  115          101.0   \n",
       "6  484176.84375  676280.2500  49.310001  124  124  115          101.0   \n",
       "7  484176.31250  676280.2500  49.340000  125  125  117          101.0   \n",
       "8  484179.12500  676280.3750  49.310001  124  126  115          101.0   \n",
       "9  484178.65625  676280.3750  49.320000  128  129  119          101.0   \n",
       "\n",
       "   ScanAngleRank  ScanDirectionFlag  NumberOfReturns  ReturnNumber  Intensity  \\\n",
       "0          -25.0                1.0              1.0           1.0       64.0   \n",
       "1          -25.0                1.0              1.0           1.0       60.0   \n",
       "2          -25.0                1.0              1.0           1.0       62.0   \n",
       "3          -25.0                1.0              1.0           1.0       64.0   \n",
       "4          -25.0                1.0              1.0           1.0       70.0   \n",
       "5          -25.0                1.0              1.0           1.0       63.0   \n",
       "6          -25.0                1.0              1.0           1.0       63.0   \n",
       "7          -25.0                1.0              1.0           1.0       57.0   \n",
       "8          -25.0                1.0              1.0           1.0       54.0   \n",
       "9          -25.0                1.0              1.0           1.0       58.0   \n",
       "\n",
       "   Classification  \n",
       "0            12.0  \n",
       "1            12.0  \n",
       "2            12.0  \n",
       "3            12.0  \n",
       "4            12.0  \n",
       "5            12.0  \n",
       "6            12.0  \n",
       "7            12.0  \n",
       "8            12.0  \n",
       "9            12.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_area = pd.read_csv('data/01.Train_Test_Area.csv', header=0, delimiter=' ')\n",
    "tt_area.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__LiDAR__ 激光点云每个点的属性定义:\n",
    "\n",
    "* __X__,__Y__ - 点的平面位置坐标,\n",
    "* __Z__ - 点的高程数据,\n",
    "* __R__,__G__,__B__ - 附加的R,G,B颜色值,\n",
    "* __PointSourceId__ - 采集来源的唯一识别值,\n",
    "* __ScanAngleRank__ - 扫描斜角,\n",
    "* __ScanDirectionFlag__ - Direction the laser scanning mirror was traveling at the time of the output laser pulse,\n",
    "* __NumberOfReturns__ - 回波次数,\n",
    "* __Intensity__ - 强度,\n",
    "* __Classification__ - 分类，如地面、植被等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 268523 entries, 0 to 268522\n",
      "Data columns (total 13 columns):\n",
      "X                    268523 non-null float64\n",
      "Y                    268523 non-null float64\n",
      "Z                    268523 non-null float64\n",
      "R                    268523 non-null int64\n",
      "G                    268523 non-null int64\n",
      "B                    268523 non-null int64\n",
      "PointSourceId        268523 non-null float64\n",
      "ScanAngleRank        268523 non-null float64\n",
      "ScanDirectionFlag    268523 non-null float64\n",
      "NumberOfReturns      268523 non-null float64\n",
      "ReturnNumber         268523 non-null float64\n",
      "Intensity            268523 non-null float64\n",
      "Classification       268523 non-null float64\n",
      "dtypes: float64(10), int64(3)\n",
      "memory usage: 26.6 MB\n"
     ]
    }
   ],
   "source": [
    "tt_area.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X                    0\n",
       "Y                    0\n",
       "Z                    0\n",
       "R                    0\n",
       "G                    0\n",
       "B                    0\n",
       "PointSourceId        0\n",
       "ScanAngleRank        0\n",
       "ScanDirectionFlag    0\n",
       "NumberOfReturns      0\n",
       "ReturnNumber         0\n",
       "Intensity            0\n",
       "Classification       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_area.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are only numerical features and that there are no null values within all data, so we can proceed with further analysis.   \n",
    "我们看到，只有数值特征，也没有空值。可以做进一步的分析了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X                    10099\n",
       "Y                     3056\n",
       "Z                     2856\n",
       "R                      233\n",
       "G                      225\n",
       "B                      228\n",
       "PointSourceId            2\n",
       "ScanAngleRank           26\n",
       "ScanDirectionFlag        1\n",
       "NumberOfReturns          5\n",
       "ReturnNumber             5\n",
       "Intensity              205\n",
       "Classification           8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_area.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>R</th>\n",
       "      <th>G</th>\n",
       "      <th>B</th>\n",
       "      <th>PointSourceId</th>\n",
       "      <th>ScanAngleRank</th>\n",
       "      <th>ScanDirectionFlag</th>\n",
       "      <th>NumberOfReturns</th>\n",
       "      <th>ReturnNumber</th>\n",
       "      <th>Intensity</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>268523.000000</td>\n",
       "      <td>268523.000000</td>\n",
       "      <td>268523.000000</td>\n",
       "      <td>268523.000000</td>\n",
       "      <td>268523.000000</td>\n",
       "      <td>268523.000000</td>\n",
       "      <td>268523.000000</td>\n",
       "      <td>268523.000000</td>\n",
       "      <td>268523.0</td>\n",
       "      <td>268523.000000</td>\n",
       "      <td>268523.000000</td>\n",
       "      <td>268523.000000</td>\n",
       "      <td>268523.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>484341.568816</td>\n",
       "      <td>676317.380434</td>\n",
       "      <td>54.626213</td>\n",
       "      <td>109.940996</td>\n",
       "      <td>113.993326</td>\n",
       "      <td>99.756259</td>\n",
       "      <td>101.999289</td>\n",
       "      <td>-4.039419</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.108453</td>\n",
       "      <td>1.054223</td>\n",
       "      <td>78.284032</td>\n",
       "      <td>2.286460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>86.110618</td>\n",
       "      <td>41.725397</td>\n",
       "      <td>3.993748</td>\n",
       "      <td>39.911418</td>\n",
       "      <td>33.695346</td>\n",
       "      <td>31.141255</td>\n",
       "      <td>0.026661</td>\n",
       "      <td>6.361055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375321</td>\n",
       "      <td>0.256920</td>\n",
       "      <td>27.867723</td>\n",
       "      <td>1.117257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>484176.312500</td>\n",
       "      <td>676222.937500</td>\n",
       "      <td>48.880001</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>484262.687500</td>\n",
       "      <td>676284.937500</td>\n",
       "      <td>51.970001</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>484350.781250</td>\n",
       "      <td>676317.500000</td>\n",
       "      <td>55.029999</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>484416.625000</td>\n",
       "      <td>676349.625000</td>\n",
       "      <td>55.770000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>484499.250000</td>\n",
       "      <td>676414.187500</td>\n",
       "      <td>78.730003</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1011.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   X              Y              Z              R  \\\n",
       "count  268523.000000  268523.000000  268523.000000  268523.000000   \n",
       "mean   484341.568816  676317.380434      54.626213     109.940996   \n",
       "std        86.110618      41.725397       3.993748      39.911418   \n",
       "min    484176.312500  676222.937500      48.880001      23.000000   \n",
       "25%    484262.687500  676284.937500      51.970001      83.000000   \n",
       "50%    484350.781250  676317.500000      55.029999     113.000000   \n",
       "75%    484416.625000  676349.625000      55.770000     133.000000   \n",
       "max    484499.250000  676414.187500      78.730003     255.000000   \n",
       "\n",
       "                   G              B  PointSourceId  ScanAngleRank  \\\n",
       "count  268523.000000  268523.000000  268523.000000  268523.000000   \n",
       "mean      113.993326      99.756259     101.999289      -4.039419   \n",
       "std        33.695346      31.141255       0.026661       6.361055   \n",
       "min        27.000000      28.000000     101.000000     -25.000000   \n",
       "25%        95.000000      81.000000     102.000000     -10.000000   \n",
       "50%       117.000000     100.000000     102.000000      -3.000000   \n",
       "75%       131.000000     113.000000     102.000000       2.000000   \n",
       "max       255.000000     255.000000     102.000000       8.000000   \n",
       "\n",
       "       ScanDirectionFlag  NumberOfReturns   ReturnNumber      Intensity  \\\n",
       "count           268523.0    268523.000000  268523.000000  268523.000000   \n",
       "mean                 1.0         1.108453       1.054223      78.284032   \n",
       "std                  0.0         0.375321       0.256920      27.867723   \n",
       "min                  1.0         1.000000       1.000000       8.000000   \n",
       "25%                  1.0         1.000000       1.000000      66.000000   \n",
       "50%                  1.0         1.000000       1.000000      79.000000   \n",
       "75%                  1.0         1.000000       1.000000      94.000000   \n",
       "max                  1.0         5.000000       5.000000    1011.000000   \n",
       "\n",
       "       Classification  \n",
       "count   268523.000000  \n",
       "mean         2.286460  \n",
       "std          1.117257  \n",
       "min          0.000000  \n",
       "25%          2.000000  \n",
       "50%          2.000000  \n",
       "75%          2.000000  \n",
       "max         12.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_area.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面，我们为后续预测研究特征重要程度。\n",
    "* 因为 __'PointSourceId'__ and __'ScanDirectionFlag'__ 列只有唯一的一个值，我们确信可以删除它们。\n",
    "* 另外， __'X'__ and __'Y'__ 坐标对每个点的值都不同，而且与不同空间区域无关也应当删除。\n",
    "\n",
    "We will use __Univariate Selection__ to confirm our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>R</th>\n",
       "      <th>G</th>\n",
       "      <th>B</th>\n",
       "      <th>PointSourceId</th>\n",
       "      <th>ScanAngleRank</th>\n",
       "      <th>ScanDirectionFlag</th>\n",
       "      <th>NumberOfReturns</th>\n",
       "      <th>ReturnNumber</th>\n",
       "      <th>Intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>484179.4375</td>\n",
       "      <td>676279.6875</td>\n",
       "      <td>49.340000</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>112</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>484179.3125</td>\n",
       "      <td>676280.0000</td>\n",
       "      <td>49.320000</td>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>115</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>484178.8125</td>\n",
       "      <td>676280.0625</td>\n",
       "      <td>49.310001</td>\n",
       "      <td>123</td>\n",
       "      <td>124</td>\n",
       "      <td>113</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>484178.3125</td>\n",
       "      <td>676280.1250</td>\n",
       "      <td>49.340000</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>112</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>484177.8125</td>\n",
       "      <td>676280.1875</td>\n",
       "      <td>49.320000</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>112</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             X            Y          Z    R    G    B  PointSourceId  \\\n",
       "0  484179.4375  676279.6875  49.340000  124  124  112          101.0   \n",
       "1  484179.3125  676280.0000  49.320000  124  125  115          101.0   \n",
       "2  484178.8125  676280.0625  49.310001  123  124  113          101.0   \n",
       "3  484178.3125  676280.1250  49.340000  122  122  112          101.0   \n",
       "4  484177.8125  676280.1875  49.320000  122  122  112          101.0   \n",
       "\n",
       "   ScanAngleRank  ScanDirectionFlag  NumberOfReturns  ReturnNumber  Intensity  \n",
       "0          -25.0                1.0              1.0           1.0       64.0  \n",
       "1          -25.0                1.0              1.0           1.0       60.0  \n",
       "2          -25.0                1.0              1.0           1.0       62.0  \n",
       "3          -25.0                1.0              1.0           1.0       64.0  \n",
       "4          -25.0                1.0              1.0           1.0       70.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tt_area.iloc[:,0:12]\n",
    "y = tt_area.iloc[:,12]\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>R</th>\n",
       "      <th>G</th>\n",
       "      <th>B</th>\n",
       "      <th>PointSourceId</th>\n",
       "      <th>ScanAngleRank</th>\n",
       "      <th>ScanDirectionFlag</th>\n",
       "      <th>NumberOfReturns</th>\n",
       "      <th>ReturnNumber</th>\n",
       "      <th>Intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>484179.4375</td>\n",
       "      <td>676279.6875</td>\n",
       "      <td>49.340000</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>112</td>\n",
       "      <td>101.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>484179.3125</td>\n",
       "      <td>676280.0000</td>\n",
       "      <td>49.320000</td>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>115</td>\n",
       "      <td>101.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>484178.8125</td>\n",
       "      <td>676280.0625</td>\n",
       "      <td>49.310001</td>\n",
       "      <td>123</td>\n",
       "      <td>124</td>\n",
       "      <td>113</td>\n",
       "      <td>101.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>484178.3125</td>\n",
       "      <td>676280.1250</td>\n",
       "      <td>49.340000</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>112</td>\n",
       "      <td>101.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>484177.8125</td>\n",
       "      <td>676280.1875</td>\n",
       "      <td>49.320000</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>112</td>\n",
       "      <td>101.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             X            Y          Z    R    G    B  PointSourceId  \\\n",
       "0  484179.4375  676279.6875  49.340000  124  124  112          101.0   \n",
       "1  484179.3125  676280.0000  49.320000  124  125  115          101.0   \n",
       "2  484178.8125  676280.0625  49.310001  123  124  113          101.0   \n",
       "3  484178.3125  676280.1250  49.340000  122  122  112          101.0   \n",
       "4  484177.8125  676280.1875  49.320000  122  122  112          101.0   \n",
       "\n",
       "   ScanAngleRank  ScanDirectionFlag  NumberOfReturns  ReturnNumber  Intensity  \n",
       "0           25.0                1.0              1.0           1.0       64.0  \n",
       "1           25.0                1.0              1.0           1.0       60.0  \n",
       "2           25.0                1.0              1.0           1.0       62.0  \n",
       "3           25.0                1.0              1.0           1.0       64.0  \n",
       "4           25.0                1.0              1.0           1.0       70.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['ScanAngleRank'] = X['ScanAngleRank'].abs() # 单变量特征选择（Univariate Selection）需要正数值\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn中的单变量特征选择\n",
    "单变量的特征选择是通过基于一些单变量的统计度量方法来选择最好的特征，比如卡方检测等。Scikit-learn 将单变量特征选择的学习器作为实现了 transform方法的对象：\n",
    "\n",
    "sklearn中实现的方法有:\n",
    "\n",
    "* SelectKBest 保留评分最高的 K 个特征\n",
    "* SelectPercentile 保留最高得分百分比之几的特征\n",
    "* 对每个特征应用常见的单变量统计测试: 假阳性率（false positive rate） SelectFpr, 伪发现率（false discovery rate） SelectFdr , 或者族系误差（family wise error） SelectFwe 。\n",
    "* GenericUnivariateSelect 允许使用可配置方法来进行单变量特征选择。它允许超参数搜索评估器来选择最好的单变量特征。\n",
    "\n",
    "这些对象将得分函数作为输入，返回单变量的得分和 p 值 （或者仅仅是 SelectKBest 和 SelectPercentile 的分数）:\n",
    "\n",
    "* 对于回归: f_regression , mutual_info_regression\n",
    "* 对于分类: chi2 , f_classif , mutual_info_classif\n",
    "\n",
    "这些基于 F-test 的方法计算两个随机变量之间的线性相关程度。另一方面，mutual information methods（mutual information : 互信息）能够计算任何种类的统计相关性，但是作为非参数的方法，互信息需要更多的样本来进行准确的估计。\n",
    "\n",
    "稀疏数据的特征选择\n",
    "\n",
    "如果你使用的是稀疏的数据 (例如数据可以由稀疏矩阵来表示), \n",
    "chi2 , mutual_info_regression , mutual_info_classif 可以处理数据并保持它的稀疏性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从12个特征中选择8个，推测可能会去掉前面提到的四个，经典的卡方检验是检验定性自变量对定性因变量的相关性。\n",
    "test = SelectKBest(score_func=chi2, k=8)\n",
    "fit = test.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.678e+02 2.203e+00 4.539e+04 1.389e+05 1.236e+05 2.676e+05 1.871e+00\n",
      " 3.398e+04 0.000e+00 1.325e+04 5.013e+02 7.182e+05]\n"
     ]
    }
   ],
   "source": [
    "print(fit.scores_) # 输出12个特征的得分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 49.34 124.   124.   112.    25.     1.     1.    64.  ]\n",
      " [ 49.32 124.   125.   115.    25.     1.     1.    60.  ]\n",
      " [ 49.31 123.   124.   113.    25.     1.     1.    62.  ]\n",
      " [ 49.34 122.   122.   112.    25.     1.     1.    64.  ]\n",
      " [ 49.32 122.   122.   112.    25.     1.     1.    70.  ]\n",
      " [ 49.32 125.   125.   115.    25.     1.     1.    63.  ]]\n"
     ]
    }
   ],
   "source": [
    "features = fit.transform(X)\n",
    "print(features[0:6,:]) # summarize selected features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8列：Z，R，G，B，扫描倾角，回波数，返回值，强度\n",
    "\n",
    "我们看到 __'PointSourceId'__ 和 __'ScanDirectionFlag'__ 几乎是空值，并且 __'X'__ 和 __'Y'__ 也不在前8名特征选择得分中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 268523 entries, 0 to 268522\n",
      "Data columns (total 13 columns):\n",
      "X                    268523 non-null float64\n",
      "Y                    268523 non-null float64\n",
      "Z                    268523 non-null float64\n",
      "R                    268523 non-null int64\n",
      "G                    268523 non-null int64\n",
      "B                    268523 non-null int64\n",
      "PointSourceId        268523 non-null float64\n",
      "ScanAngleRank        268523 non-null float64\n",
      "ScanDirectionFlag    268523 non-null float64\n",
      "NumberOfReturns      268523 non-null float64\n",
      "ReturnNumber         268523 non-null float64\n",
      "Intensity            268523 non-null float64\n",
      "Classification       268523 non-null float64\n",
      "dtypes: float64(10), int64(3)\n",
      "memory usage: 26.6 MB\n"
     ]
    }
   ],
   "source": [
    "tt_area.info()\n",
    "tt_area.drop(['PointSourceId', 'ScanDirectionFlag', 'X', 'Y'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面分析 __'Classification'__ 特征。\n",
    "\n",
    "一般的LiDAR数据分类有18种类别代码：\n",
    "* __0__ / __1__ - 尚未分类 / 未指定,\n",
    "* __2__ - 地面,\n",
    "* __3__ / __4__ / __5__ - 低植被 / 中植被 / 高植被,\n",
    "* __6__ - 建筑,\n",
    "* __7__ - 噪音,\n",
    "* __8__ - Model Key,\n",
    "* __9__ - 水,\n",
    "* __10__ / __11__ - 铁路 / 道路(表面),\n",
    "* __12__ - Overlap (保留),\n",
    "* __13__ / __14__ / __15__ / __16__ - Wire-Guard / Wire-Conductor / Transmission Tower / Wire-Connector\n",
    "* __17__ - Bridge Deck\n",
    "* __18__ - High Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  2.,  3.,  4.,  5.,  6.,  7., 12.]),\n",
       " array([  9073, 226767,   5630,   2924,  14076,   9859,      3,    191]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(tt_area.Classification, return_counts=True) # 计算每个类别有多少记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "#plt.hist(tt_area.Classification, color = 'skyblue')\n",
    "#plt.title(u'LiDAR - Histogram')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "如图所示，极大比例的是地面(2)类别点。这是一个失调的比例，会明显降低性能。另外，也没有1和8以上的类别。\n",
    "\n",
    "### 1.2 数据采样\n",
    "\n",
    "对主要类别 - 地面（2）采用 __down-sampling__ ，对其它了别采用 __up-sampling__ , 设置所有类别的采样数量匹配 __5000 features__ 。\n",
    "针对少数类的向上采样和针对多数类的向下采样都使用来自 https://elitedatascience.com/imbalanced-classes 模式。\n",
    "首先，我们必须把数据切分成 __train / test__ 数据集，以免干扰后面基于测试数据的模型精确度评估。\n",
    "\n",
    "关于不平衡类别处理参考文章 https://yq.aliyun.com/articles/226016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Z</th>\n",
       "      <th>R</th>\n",
       "      <th>G</th>\n",
       "      <th>B</th>\n",
       "      <th>ScanAngleRank</th>\n",
       "      <th>NumberOfReturns</th>\n",
       "      <th>ReturnNumber</th>\n",
       "      <th>Intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.340000</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>112</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.320000</td>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>115</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.310001</td>\n",
       "      <td>123</td>\n",
       "      <td>124</td>\n",
       "      <td>113</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.340000</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>112</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.320000</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>112</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Z    R    G    B  ScanAngleRank  NumberOfReturns  ReturnNumber  \\\n",
       "0  49.340000  124  124  112          -25.0              1.0           1.0   \n",
       "1  49.320000  124  125  115          -25.0              1.0           1.0   \n",
       "2  49.310001  123  124  113          -25.0              1.0           1.0   \n",
       "3  49.340000  122  122  112          -25.0              1.0           1.0   \n",
       "4  49.320000  122  122  112          -25.0              1.0           1.0   \n",
       "\n",
       "   Intensity  \n",
       "0       64.0  \n",
       "1       60.0  \n",
       "2       62.0  \n",
       "3       64.0  \n",
       "4       70.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tt_area.iloc[:,0:8]\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12.0\n",
       "1    12.0\n",
       "2    12.0\n",
       "3    12.0\n",
       "4    12.0\n",
       "Name: Classification, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = tt_area.iloc[:,8]\n",
    "y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we concatenate our X_train and y_train data in order to handle our imbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Z    R    G    B  ScanAngleRank  NumberOfReturns  \\\n",
      "206916  50.200001   85  121   95          -14.0              1.0   \n",
      "190480  55.430000  122  126  109           -5.0              1.0   \n",
      "183167  53.270000  167  159  149           -8.0              1.0   \n",
      "167392  51.180000  151  147  115          -11.0              1.0   \n",
      "186184  54.810001  115  119   94           -5.0              1.0   \n",
      "\n",
      "        ReturnNumber  Intensity  Classification  \n",
      "206916           1.0       71.0             2.0  \n",
      "190480           1.0       63.0             2.0  \n",
      "183167           1.0      116.0             2.0  \n",
      "167392           1.0       72.0             2.0  \n",
      "186184           1.0       72.0             2.0  \n"
     ]
    }
   ],
   "source": [
    "tt_area_train = pd.concat([X_train, y_train], axis=1, join='inner')\n",
    "print(tt_area_train.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0     151850\n",
      "5.0       9508\n",
      "6.0       6684\n",
      "0.0       6067\n",
      "3.0       3772\n",
      "4.0       1894\n",
      "12.0       133\n",
      "7.0          2\n",
      "Name: Classification, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(tt_area_train.Classification.value_counts()) # train data imbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 123\n",
    "n_samples = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_area_majority_2 = tt_area_train[tt_area_train.Classification==2] # 提取地面特征记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25000 entries, 257290 to 90134\n",
      "Data columns (total 9 columns):\n",
      "Z                  25000 non-null float64\n",
      "R                  25000 non-null int64\n",
      "G                  25000 non-null int64\n",
      "B                  25000 non-null int64\n",
      "ScanAngleRank      25000 non-null float64\n",
      "NumberOfReturns    25000 non-null float64\n",
      "ReturnNumber       25000 non-null float64\n",
      "Intensity          25000 non-null float64\n",
      "Classification     25000 non-null float64\n",
      "dtypes: float64(6), int64(3)\n",
      "memory usage: 1.9 MB\n"
     ]
    }
   ],
   "source": [
    "# 地面点从15万减到2.5万\n",
    "tt_area_majority_2_upsampled = resample(tt_area_majority_2, \n",
    "                                 replace=False,              # 采样替换，采用切片方式；采样数不能超出原来数据表记录数\n",
    "                                 n_samples=n_samples,        # n_samples chosen for down-sampling\n",
    "                                 random_state=random_state)  # reproducible results\n",
    "tt_area_majority_2_upsampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_area_minority_0 = tt_area_train[tt_area_train.Classification==0] # extraction of Never classified features\n",
    "tt_area_minority_3 = tt_area_train[tt_area_train.Classification==3] # extraction of Low Vegetation features\n",
    "tt_area_minority_4 = tt_area_train[tt_area_train.Classification==4] # extraction of Medium Vegetation features\n",
    "tt_area_minority_5 = tt_area_train[tt_area_train.Classification==5] # extraction of High Vegetation features\n",
    "tt_area_minority_6 = tt_area_train[tt_area_train.Classification==6] # extraction of Building features\n",
    "tt_area_minority_7 = tt_area_train[tt_area_train.Classification==7] # extraction of Noise features\n",
    "tt_area_minority_12 = tt_area_train[tt_area_train.Classification==12] # extraction of Overlap (Reserved) features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 少数类增加到与多数类同样的样本数2.5万\n",
    "tt_area_minority_0_upsampled = resample(tt_area_minority_0, \n",
    "                                 replace=True,               # sample with replacement\n",
    "                                 n_samples=n_samples,        # to match majority class\n",
    "                                 random_state=random_state)  # reproducible results\n",
    "\n",
    "tt_area_minority_3_upsampled = resample(tt_area_minority_3, \n",
    "                                 replace=True,               # sample with replacement\n",
    "                                 n_samples=n_samples,        # to match majority class\n",
    "                                 random_state=random_state)  # reproducible results\n",
    "\n",
    "tt_area_minority_4_upsampled = resample(tt_area_minority_4, \n",
    "                                 replace=True,               # sample with replacement\n",
    "                                 n_samples=n_samples,        # to match majority class\n",
    "                                 random_state=random_state)  # reproducible results\n",
    "\n",
    "tt_area_minority_5_upsampled = resample(tt_area_minority_5, \n",
    "                                 replace=True,               # sample with replacement\n",
    "                                 n_samples=n_samples,        # to match majority class\n",
    "                                 random_state=random_state)  # reproducible results\n",
    "\n",
    "tt_area_minority_6_upsampled = resample(tt_area_minority_6, \n",
    "                                 replace=True,               # sample with replacement\n",
    "                                 n_samples=n_samples,        # to match majority class\n",
    "                                 random_state=random_state)  # reproducible results\n",
    "\n",
    "tt_area_minority_7_upsampled = resample(tt_area_minority_7, \n",
    "                                 replace=True,               # sample with replacement\n",
    "                                 n_samples=n_samples,        # to match majority class\n",
    "                                 random_state=random_state)  # reproducible results\n",
    "\n",
    "tt_area_minority_12_upsampled = resample(tt_area_minority_12, \n",
    "                                 replace=True,               # sample with replacement\n",
    "                                 n_samples=n_samples,        # to match majority class\n",
    "                                 random_state=random_state)  # reproducible results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在合并生成采样数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_area_train_sampled = pd.concat([tt_area_minority_0_upsampled, tt_area_majority_2_upsampled, \n",
    "                                     tt_area_minority_3_upsampled, tt_area_minority_4_upsampled, \n",
    "                                     tt_area_minority_5_upsampled, tt_area_minority_6_upsampled, \n",
    "                                     tt_area_minority_7_upsampled, tt_area_minority_12_upsampled ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载训练数据集有了更多观察值，而各个类别的数据比例都是1:1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 200000 entries, 41499 to 111\n",
      "Data columns (total 9 columns):\n",
      "Z                  200000 non-null float64\n",
      "R                  200000 non-null int64\n",
      "G                  200000 non-null int64\n",
      "B                  200000 non-null int64\n",
      "ScanAngleRank      200000 non-null float64\n",
      "NumberOfReturns    200000 non-null float64\n",
      "ReturnNumber       200000 non-null float64\n",
      "Intensity          200000 non-null float64\n",
      "Classification     200000 non-null float64\n",
      "dtypes: float64(6), int64(3)\n",
      "memory usage: 15.3 MB\n"
     ]
    }
   ],
   "source": [
    "tt_area_train_sampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0     25000\n",
       "12.0    25000\n",
       "5.0     25000\n",
       "6.0     25000\n",
       "4.0     25000\n",
       "3.0     25000\n",
       "2.0     25000\n",
       "0.0     25000\n",
       "Name: Classification, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_area_train_sampled.Classification.value_counts() # 现在训练数据集有20万个点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tt_area_train_sampled.iloc[:, :8] # 特征数据\n",
    "y_train = tt_area_train_sampled.iloc[:, 8] # 分类数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理=》无量纲化=》区间缩放法：区间缩放法的思路有多种，常见的一种为利用两个最值进行缩放\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huhongjun/anaconda2/envs/MLvsLiDAR/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/huhongjun/anaconda2/envs/MLvsLiDAR/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.176, 0.348, 0.417, ..., 0.   , 0.   , 0.11 ],\n",
       "       [0.185, 0.991, 0.978, ..., 0.   , 0.   , 0.058],\n",
       "       [0.109, 0.365, 0.48 , ..., 0.   , 0.   , 0.059],\n",
       "       ...,\n",
       "       [0.206, 0.483, 0.386, ..., 0.   , 0.   , 0.13 ],\n",
       "       [0.007, 0.396, 0.413, ..., 0.   , 0.   , 0.078],\n",
       "       [0.086, 0.852, 0.798, ..., 0.   , 0.   , 0.113]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = mm.fit_transform(X_train) # 采样之后的全部数据集：训练+测试=》再采样\n",
    "X_test = mm.fit_transform(X_test) # sklearn最早分出来的测试集\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 XGBoost - 默认\n",
    "\n",
    "下面我们采用梯度增强算法的一个高级实现 - __XGBoost__ 。\n",
    "\n",
    "先用默认设置(we will work only with scaled data from now on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.98%\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1, tree_method='gpu_hist')\n"
     ]
    }
   ],
   "source": [
    "model_xgb = XGBClassifier(tree_method='gpu_hist')\n",
    "model_xgb.fit(X_train, y_train)\n",
    "y_pred = model_xgb.predict(X_train)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_train, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print(model_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.93%\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_xgb.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "超过78%的准确度已经不错。不过有5%的准确度下降，可能有过度拟合的问题。\n",
    "\n",
    "\n",
    "### 1.4 XGBoost - 调参\n",
    "\n",
    "\n",
    "下面调整XGBoost参数，看能否在训练和测试数据上火的更好的准确度。\n",
    "文章 https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/ 中的内容将作为优化的参考。\n",
    "\n",
    "需要执行的几个步骤：\n",
    "\n",
    "1. 选择默认值 __learning rate__ 和 __number of trees__\n",
    "2. 调整 __max_depth__ 和 __min_child_weight__\n",
    "3. 调整 __gamma__\n",
    "4. 调整 __subsample__ 和 __colsample_bytree__\n",
    "5. 调整 __regularization parameters__\n",
    "6. 降低 __learning rate__ 和提升 __more trees__\n",
    "\n",
    "看看更详细的每一步操作方法。\n",
    "\n",
    "首先，设置默认值：\n",
    "* learning rate - 0.1   一般情况下，学习速率的值为0.1。\n",
    "* number of trees - 100,\n",
    "\n",
    "其它参数优化后，会有什么变化呢？\n",
    "\n",
    "下面设置 __GridSearchCV__ 为 __5 cross-validation__ ， __max_depth__ 和 __min_child_weight__ as they will most likely have the highest impact on model outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV] max_depth=5, min_child_weight=1 .................................\n",
      "[CV] .. max_depth=5, min_child_weight=1, score=0.870325, total=   7.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.1s remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=1 .................................\n",
      "[CV] .. max_depth=5, min_child_weight=1, score=0.869575, total=   7.1s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   14.3s remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=1 .................................\n",
      "[CV] ... max_depth=5, min_child_weight=1, score=0.87045, total=   6.9s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   21.3s remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=1 .................................\n",
      "[CV] ... max_depth=5, min_child_weight=1, score=0.86665, total=   6.8s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   28.1s remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=1 .................................\n",
      "[CV] .... max_depth=5, min_child_weight=1, score=0.8704, total=   6.8s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   34.9s remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=3 .................................\n",
      "[CV] ... max_depth=5, min_child_weight=3, score=0.87085, total=   6.8s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   41.8s remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=3 .................................\n",
      "[CV] .... max_depth=5, min_child_weight=3, score=0.8695, total=   6.7s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   48.6s remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=3 .................................\n",
      "[CV] .. max_depth=5, min_child_weight=3, score=0.869125, total=   7.1s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   55.7s remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=3 .................................\n",
      "[CV] ... max_depth=5, min_child_weight=3, score=0.86665, total=   7.3s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.1min remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=3 .................................\n",
      "[CV] .. max_depth=5, min_child_weight=3, score=0.868875, total=   7.3s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.2min remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV] .... max_depth=5, min_child_weight=5, score=0.8713, total=   7.1s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:  1.3min remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV] .... max_depth=5, min_child_weight=5, score=0.8687, total=   7.2s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  1.4min remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV] ... max_depth=5, min_child_weight=5, score=0.86885, total=   6.9s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:  1.5min remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV] .. max_depth=5, min_child_weight=5, score=0.866125, total=   6.9s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:  1.6min remaining:    0.0s\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV] ... max_depth=5, min_child_weight=5, score=0.87005, total=   7.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  1.8min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=1 ................................\n",
      "[CV] . max_depth=10, min_child_weight=1, score=0.952925, total=  12.6s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:  2.0min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=1 ................................\n",
      "[CV] .. max_depth=10, min_child_weight=1, score=0.95495, total=  12.5s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:  2.2min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=1 ................................\n",
      "[CV] . max_depth=10, min_child_weight=1, score=0.953575, total=  12.6s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  2.4min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=1 ................................\n",
      "[CV] ... max_depth=10, min_child_weight=1, score=0.9525, total=  12.7s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:  2.6min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=1 ................................\n",
      "[CV] .. max_depth=10, min_child_weight=1, score=0.95465, total=  12.5s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  2.8min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=3 ................................\n",
      "[CV] . max_depth=10, min_child_weight=3, score=0.951275, total=  12.0s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:  3.0min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=3 ................................\n",
      "[CV] . max_depth=10, min_child_weight=3, score=0.951025, total=  11.8s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:  3.2min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=3 ................................\n",
      "[CV] . max_depth=10, min_child_weight=3, score=0.951625, total=  11.9s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:  3.4min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=3 ................................\n",
      "[CV] ... max_depth=10, min_child_weight=3, score=0.9496, total=  12.9s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  3.6min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=3 ................................\n",
      "[CV] ... max_depth=10, min_child_weight=3, score=0.9527, total=  12.0s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  3.8min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=5 ................................\n",
      "[CV] ... max_depth=10, min_child_weight=5, score=0.9463, total=  11.5s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:  4.0min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=5 ................................\n",
      "[CV] ... max_depth=10, min_child_weight=5, score=0.9481, total=  12.1s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  4.2min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=5 ................................\n",
      "[CV] ... max_depth=10, min_child_weight=5, score=0.9479, total=  11.5s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:  4.4min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=5 ................................\n",
      "[CV] ... max_depth=10, min_child_weight=5, score=0.9481, total=  12.2s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:  4.6min remaining:    0.0s\n",
      "[CV] max_depth=10, min_child_weight=5 ................................\n",
      "[CV] . max_depth=10, min_child_weight=5, score=0.948875, total=  11.5s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  4.8min remaining:    0.0s\n",
      "[CV] max_depth=20, min_child_weight=1 ................................\n",
      "[CV] ... max_depth=20, min_child_weight=1, score=0.9881, total=  39.8s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:  5.5min remaining:    0.0s\n",
      "[CV] max_depth=20, min_child_weight=1 ................................\n",
      "[CV] ... max_depth=20, min_child_weight=1, score=0.9889, total=  40.1s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:  6.2min remaining:    0.0s\n",
      "[CV] max_depth=20, min_child_weight=1 ................................\n",
      "[CV] . max_depth=20, min_child_weight=1, score=0.989275, total=  39.9s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:  6.8min remaining:    0.0s\n",
      "[CV] max_depth=20, min_child_weight=1 ................................\n",
      "[CV] .. max_depth=20, min_child_weight=1, score=0.98875, total=  41.1s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:  7.5min remaining:    0.0s\n",
      "[CV] max_depth=20, min_child_weight=1 ................................\n",
      "[CV] . max_depth=20, min_child_weight=1, score=0.989075, total=  40.6s\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:  8.2min remaining:    0.0s\n",
      "[CV] max_depth=20, min_child_weight=3 ................................\n",
      "[CV] . max_depth=20, min_child_weight=3, score=0.987175, total=  32.3s\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  8.7min remaining:    0.0s\n",
      "[CV] max_depth=20, min_child_weight=3 ................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... max_depth=20, min_child_weight=3, score=0.9874, total=  33.4s\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:  9.3min remaining:    0.0s\n",
      "[CV] max_depth=20, min_child_weight=3 ................................\n",
      "[CV] .. max_depth=20, min_child_weight=3, score=0.98735, total=  31.9s\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:  9.8min remaining:    0.0s\n",
      "[CV] max_depth=20, min_child_weight=3 ................................\n",
      "[CV] . max_depth=20, min_child_weight=3, score=0.987075, total=  32.1s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed: 10.4min remaining:    0.0s\n",
      "[CV] max_depth=20, min_child_weight=3 ................................\n",
      "[CV] . max_depth=20, min_child_weight=3, score=0.987875, total=  34.7s\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed: 10.9min remaining:    0.0s\n",
      "[CV] max_depth=20, min_child_weight=5 ................................\n",
      "[CV] .. max_depth=20, min_child_weight=5, score=0.98495, total=  29.3s\n",
      "[Parallel(n_jobs=1)]: Done  41 out of  41 | elapsed: 11.4min remaining:    0.0s\n",
      "[CV] max_depth=20, min_child_weight=5 ................................\n",
      "[CV] . max_depth=20, min_child_weight=5, score=0.985525, total=  28.7s\n",
      "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed: 11.9min remaining:    0.0s\n",
      "[CV] max_depth=20, min_child_weight=5 ................................\n",
      "[CV] . max_depth=20, min_child_weight=5, score=0.985275, total=  29.0s\n",
      "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed: 12.4min remaining:    0.0s\n",
      "[CV] max_depth=20, min_child_weight=5 ................................\n",
      "[CV] . max_depth=20, min_child_weight=5, score=0.985625, total=  30.2s\n",
      "[Parallel(n_jobs=1)]: Done  44 out of  44 | elapsed: 12.9min remaining:    0.0s\n",
      "[CV] max_depth=20, min_child_weight=5 ................................\n",
      "[CV] . max_depth=20, min_child_weight=5, score=0.985675, total=  29.6s\n",
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed: 13.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed: 13.4min finished\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'grid_scores_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-919006e8fa18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mgscv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgscv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'grid_scores_'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "params = {\n",
    "    'max_depth':[5,10,20],\n",
    "    'min_child_weight':[1,3,5]\n",
    "}\n",
    "\n",
    "gscv1 = GridSearchCV(estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "                                            colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "                                            missing=None, n_estimators=100, n_jobs=1, nthread=None, \n",
    "                                            objective='multi:softprob', random_state=0, reg_alpha=0, reg_lambda=1,\n",
    "                                            scale_pos_weight=1, seed=None, silent=True, subsample=1,tree_method='gpu_hist'),\n",
    "                                            param_grid = params, cv=5, verbose=100)\n",
    "\n",
    "\n",
    "gscv1.fit(X_train,y_train)\n",
    "\n",
    "s = gscv1.grid_scores_.copy()\n",
    "s.sort(key= lambda x: x[1],reverse=True)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s = gscv1.cv_results_.copy()\n",
    "#s.sort(key= lambda x: x[1],reverse=True)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see 20 as the optimal value for __max_depth__ and  for __min_child_weight__ and because these are our extreme values we will search for more precise values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(**gscv1.best_params_,tree_method='gpu_hist')\n",
    "params = {'max_depth': [20,30,40,50],\n",
    "         'min_child_weight': [1,2]}\n",
    "gscv2 = GridSearchCV(param_grid=params, estimator=xgb,cv=5, verbose=100)\n",
    "gscv2.fit(X_train,y_train)\n",
    "s = gscv2.grid_scores_.copy()\n",
    "s.sort(key= lambda x: x[1],reverse=True)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We will go one step deeper once more and look for optimum values for max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(**gscv2.best_estimator_.get_params())\n",
    "params = {'max_depth': [50,60,70,80]\n",
    "         }\n",
    "gscv3 = GridSearchCV(param_grid=params, estimator=xgb,cv=5, verbose=100)\n",
    "gscv3.fit(X_train,y_train)\n",
    "s = gscv3.grid_scores_.copy()\n",
    "s.sort(key= lambda x: x[1],reverse=True)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see that picking __50 max_depth__ value was the right way to go. So now we've got the optimum values of __50__ for __max_depth__ and __1__ for __min_child_weight__.\n",
    "\n",
    "Subsequently we will tune __gamma value__ using the parameters already tuned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(**gscv3.best_estimator_.get_params())\n",
    "params = {'gamma':[0.0,0.1,0.2,0.3,0.4]\n",
    "          \n",
    "         }\n",
    "gscv4 = GridSearchCV(param_grid=params, estimator=xgb,cv=5, verbose=100)\n",
    "gscv4.fit(X_train,y_train)\n",
    "s = gscv4.grid_scores_.copy()\n",
    "s.sort(key= lambda x: x[1],reverse=True)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We've got the optimum value of __0.0__ for __gamma__ parameter.\n",
    "\n",
    "Next we will tune __subsample__ and __colsample_bytree__ with values 0.6, 0.7, 0.8, 0.9 for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(**gscv4.best_estimator_.get_params())\n",
    "params = {'subsample':[0.6,0.7,0.8,0.9],\n",
    "         'colsample_bytree':[0.6,0.7,0.8,0.9]\n",
    "\n",
    "         }\n",
    "gscv5 = GridSearchCV(param_grid=params, estimator=xgb,cv=5, verbose=100)\n",
    "gscv5.fit(X_train,y_train)\n",
    "s = gscv5.grid_scores_.copy()\n",
    "s.sort(key= lambda x: x[1],reverse=True)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see that __colsample_bytree__: 0.6 and __subsample__: 0.9 were the most optimum values.\n",
    "\n",
    "Now we will apply regularization (__reg_alpha, reg_lambda__) to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(**gscv5.best_estimator_.get_params())\n",
    "params = {'reg_alpha':[1e-5, 1e-2, 0, 0.1, 1, 100],\n",
    "          \n",
    "        }\n",
    "\n",
    "gscv6 = GridSearchCV(param_grid=params, estimator=xgb,cv=5, verbose=100)\n",
    "gscv6.fit(X_train,y_train)\n",
    "s = gscv6.grid_scores_.copy()\n",
    "s.sort(key= lambda x: x[1],reverse=True)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We've got an extreme value of 1e-05 so we will do more investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(**gscv6.best_estimator_.get_params())\n",
    "params = {'reg_alpha':[1e-9, 1e-7, 1e-5, 1e-3]\n",
    "          \n",
    "        }\n",
    "\n",
    "gscv7 = GridSearchCV(param_grid=params, estimator=xgb,cv=5, verbose=100)\n",
    "gscv7.fit(X_train,y_train)\n",
    "s = gscv7.grid_scores_.copy()\n",
    "s.sort(key= lambda x: x[1],reverse=True)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next we focus on __reg_lambda__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(**gscv7.best_estimator_.get_params())\n",
    "params = {'reg_lambda':[1e-5, 1e-2, 0, 0.1, 1, 100],\n",
    "          \n",
    "        }\n",
    "\n",
    "gscv8 = GridSearchCV(param_grid=params, estimator=xgb,cv=5, verbose=100)\n",
    "gscv8.fit(X_train,y_train)\n",
    "s = gscv8.grid_scores_.copy()\n",
    "s.sort(key= lambda x: x[1],reverse=True)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As well as in reg_alpha we've got the extreme value of 1e-05 so we do more searching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(**gscv8.best_estimator_.get_params())\n",
    "params = {'reg_lambda':[1e-9, 1e-7, 1e-5, 1e-3]\n",
    "          \n",
    "        }\n",
    "\n",
    "gscv9 = GridSearchCV(param_grid=params, estimator=xgb,cv=5, verbose=100)\n",
    "gscv9.fit(X_train,y_train)\n",
    "s = gscv9.grid_scores_.copy()\n",
    "s.sort(key= lambda x: x[1],reverse=True)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see that __creg_alpha__: 1e-05 and __reg_lambda__: 0.001 were the most optimum values.\n",
    "\n",
    "Finally we've achieved our optimal XGBoost algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gscv9.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we should lower the __learning rate__ to 0.01 and add more __trees__ - 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "                           colsample_bytree=0.6, gamma=0.0, learning_rate=0.01,\n",
    "                           max_delta_step=0, max_depth=50, min_child_weight=1, missing=None,\n",
    "                           n_estimators=1000, n_jobs=1, nthread=None,\n",
    "                           objective='multi:softprob', random_state=0, reg_alpha=1e-07,\n",
    "                           reg_lambda=0.001, scale_pos_weight=1, seed=None, silent=True,\n",
    "                           subsample=0.9)\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_train)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_train, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A score of over 87%.\n",
    "\n",
    "Summarizing our tuned XGBoost algorithm got the best score for training and test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.测试数据集\n",
    "\n",
    "### 2.1 数据分析\n",
    "\n",
    "测试区域有46973点云数据，面积9896平米。\n",
    "\n",
    "<img src='img/Zakres2_2d.jpg' width=\"80%\">\n",
    "<img src='img/Zakres2_3d.jpg' width=\"80%\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_area = pd.read_csv('data/01.Test_Area.csv', header=0, delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_area.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_area.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in test area there are also only numerical features and that there are no null values within all data, so we can proceed with further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_area.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_area.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_area = t_area.drop(['PointSourceId', 'ScanDirectionFlag', 'X', 'Y'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = t_area.iloc[:,0:8]\n",
    "y2 = t_area.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(t_area.Classification, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(t_area.Classification, color = 'skyblue')\n",
    "\n",
    "plt.title('LiDAR points in each class')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = mm.fit_transform(X2) #we scale our data as in the first train/test area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 XGBoost - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_pred = model_xgb.predict(X2)\n",
    "predictions2 = [round(value) for value in y2_pred]\n",
    "accuracy = accuracy_score(y2, predictions2)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 XGBoost - tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_pred = best_model.predict(X2)\n",
    "predictions2 = [round(value) for value in y2_pred]\n",
    "accuracy = accuracy_score(y2, predictions2)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 54% ! So summarizing accuracies on X2, y2 test areas were really low in comparisson to X_test and y_test data from train/test area.\n",
    "\n",
    "We will split our test area dataset to train, test data to see how our optimized XGBoost model works fitted on X2_train, y2_train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size = 0.33)\n",
    "X2_train = mm.fit_transform(X2_train)\n",
    "X2_test = mm.fit_transform(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "                           colsample_bytree=0.6, gamma=0.0, learning_rate=0.01,\n",
    "                           max_delta_step=0, max_depth=50, min_child_weight=1, missing=None,\n",
    "                           n_estimators=1000, n_jobs=1, nthread=None,\n",
    "                           objective='multi:softprob', random_state=0, reg_alpha=1e-07,\n",
    "                           reg_lambda=0.001, scale_pos_weight=1, seed=None, silent=True,\n",
    "                           subsample=0.9)\n",
    "\n",
    "best_model.fit(X2_train, y2_train)\n",
    "y2_pred = best_model.predict(X2_train)\n",
    "predictions = [round(value) for value in y2_pred]\n",
    "accuracy = accuracy_score(y2_train, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have achieved perfect score on train test area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_pred = best_model.predict(X2_test)\n",
    "predictions = [round(value) for value in y2_pred]\n",
    "accuracy = accuracy_score(y2_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And almost 95% on test dataset! In conclusion two factors maybe to blame here.\n",
    "\n",
    "First the chosen features were not optimal and we should try a pick other than __Univariate Selection__.\n",
    "\n",
    "The second is that we only had one train/test area and our test area may have varied too much to achieve good result. With better hardware capabilities we could have chosen over a dozen of train/test areas and fit combined data into our algorithm.\n",
    "\n",
    "To wrap things up there will be consecutive notebook __\"02. XGBoost for Aerial LiDAR Data Classification with extended training dataset\"__ where __XGBoost__ algorithm  will be trained an fit on __6 training areas__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6(MLvsLiDAR)",
   "language": "python",
   "name": "mlvslidar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
